{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "1. training_mask_detection_model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCiTyVTyn6qv"
      },
      "source": [
        "# TRAINING FACE MASK DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m67oyMVDn6qw"
      },
      "source": [
        "## IMPORTING NECESSARY LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHj_QjPun6qw"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSuB893cpUxY"
      },
      "source": [
        "### Mounting Drive & Importing DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCUtwDCtpSKg",
        "outputId": "1397de86-9535-408f-bb70-bb020c51453a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzcMY1In6qx"
      },
      "source": [
        "INIT_LR = 1e-4\n",
        "EPOCHS = 20\n",
        "BS = 32\n",
        "directory=\"/content/gdrive/MyDrive/Colab Notebooks/Face Mask dataset\"\n",
        "categories=[\"with_mask\",\"without_mask\"]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDXrsmyrn6qx",
        "outputId": "a89fc9b6-0852-4677-db79-b1a74b765540"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for imagePath in categories:\n",
        "    path=os.path.join(directory,imagePath)\n",
        "    for img in os.listdir(path):\n",
        "        img_path=os.path.join(path,img)\n",
        "        image = load_img(img_path, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "        data.append(image)\n",
        "        labels.append(imagePath)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X0WDJzOn6q3"
      },
      "source": [
        "### PERFORMING ONE HOT ENCODING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXXF2VXEn6q3"
      },
      "source": [
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvP__5BKn6q3"
      },
      "source": [
        "### PARTIONING THE DATA INTO TRAINING AND TESTING SPLITS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mImoK1Ain6q3"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NROEcj-Wn6q3",
        "outputId": "9bc2bd6f-8c47-4656-96d1-c52e8d0623eb"
      },
      "source": [
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "                        input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FgAXyR0n6q4",
        "outputId": "d3bc825f-924a-4e3e-a5cd-b7552c6160fe"
      },
      "source": [
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9SDzZopn6q5",
        "outputId": "46cdb120-cccd-4b47-9ec1-61be6fbc127a"
      },
      "source": [
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "    aug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)\n",
        "\n",
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/20\n",
            "96/96 [==============================] - 34s 354ms/step - loss: 0.3691 - accuracy: 0.8321 - val_loss: 0.1079 - val_accuracy: 0.9727\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - 33s 343ms/step - loss: 0.1096 - accuracy: 0.9622 - val_loss: 0.0725 - val_accuracy: 0.9779\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - 33s 344ms/step - loss: 0.0774 - accuracy: 0.9757 - val_loss: 0.0578 - val_accuracy: 0.9805\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - 33s 343ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 0.0640 - val_accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0587 - accuracy: 0.9790 - val_loss: 0.0545 - val_accuracy: 0.9792\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - 33s 342ms/step - loss: 0.0537 - accuracy: 0.9819 - val_loss: 0.0501 - val_accuracy: 0.9805\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.0490 - val_accuracy: 0.9818\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - 33s 340ms/step - loss: 0.0464 - accuracy: 0.9846 - val_loss: 0.0569 - val_accuracy: 0.9766\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.0471 - val_accuracy: 0.9844\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - 33s 340ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.0475 - val_accuracy: 0.9831\n",
            "Epoch 11/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9792\n",
            "Epoch 12/20\n",
            "96/96 [==============================] - 33s 344ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0510 - val_accuracy: 0.9805\n",
            "Epoch 13/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0419 - val_accuracy: 0.9870\n",
            "Epoch 14/20\n",
            "96/96 [==============================] - 33s 340ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
            "Epoch 15/20\n",
            "96/96 [==============================] - 33s 340ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0488 - val_accuracy: 0.9831\n",
            "Epoch 16/20\n",
            "96/96 [==============================] - 33s 340ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.0389 - val_accuracy: 0.9870\n",
            "Epoch 17/20\n",
            "96/96 [==============================] - 33s 342ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0365 - val_accuracy: 0.9883\n",
            "Epoch 18/20\n",
            "96/96 [==============================] - 33s 341ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.0355 - val_accuracy: 0.9883\n",
            "Epoch 19/20\n",
            "96/96 [==============================] - 33s 342ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.0380 - val_accuracy: 0.9870\n",
            "Epoch 20/20\n",
            "96/96 [==============================] - 33s 342ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0400 - val_accuracy: 0.9870\n",
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YnJ9nipn6q6"
      },
      "source": [
        "### CLASSIFICATION REPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJRhnYFXn6q6",
        "outputId": "0047c11f-fcdc-4b4f-97c5-030ed036765f"
      },
      "source": [
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=lb.classes_))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_mask       0.98      0.99      0.99       384\n",
            "without_mask       0.99      0.98      0.99       386\n",
            "\n",
            "    accuracy                           0.99       770\n",
            "   macro avg       0.99      0.99      0.99       770\n",
            "weighted avg       0.99      0.99      0.99       770\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}